<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.84.0"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Ethical AI Tool Landscape</title><link rel=stylesheet href=https://edwinwenink.github.io/ai-ethics-tool-landscape/css/style.css><link rel=alternate type=application/rss+xml href=https://edwinwenink.github.io/ai-ethics-tool-landscape/index.xml title="Ethical AI Tool Landscape"></head><body><header><div class=inline-block><a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape target=_blank><img src=https://edwinwenink.github.io/ai-ethics-tool-landscape/img/GitHub-Mark/PNG/GitHub-Mark-32px.png alt="Github page" class=inline-logo></a></div><nav><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/>Values</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/>Stages</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/taxonomy/>Taxonomy</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/>Tools</a></nav></header><main><h1 class=title>AI Ethics Tool Landscape</h1><p>This <b>open source</b> and <b>plain-text</b> project provides a <b>taxonomy</b> for the existing <b>tool landscape</b> for <b>ethical</b> and <b>trustworthy</b> Artificial Intelligence (<b>AI</b>).</p><p>You can find tools using high-level concepts, such as the <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/>value</a> they support, or the <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/>project stage</a> in which a tool is applicable.
But you can use many fine-grained distinctions as well.
For example, you can distinguish tools based on the <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tasks/>machine learning tasks</a>, the <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/data/>data type</a> or the <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/languages/>programming languages</a> they support.
Explainability tools output various <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/>types of explanation</a> and fairness tools may assume different <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/fairness/>types of fairness</a>.
Some tools are <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/categories/model-agnostic>model-agnostic</a> whereas others can only be used in combination with <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/categories/model-specific>specific types of models</a>.
For more an overview of all taxonomy terms, visit the <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/taxonomy/>taxonomy</a> page.</p><p>See the <a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape target=_blank>project page</a> on how to <b>contribute</b> to this project.</p><h2><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/>Values</a></h2><div class=values><ul><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/accountability/>Accountability</a> (9)</li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/explainability/>Explainability</a> (8)</li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/fairness/>Fairness</a> (8)</li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/privacy/>Privacy</a> (2)</li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/security/>Security</a> (1)</li></ul></div><h2><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/>Stages</a></h2><div class=stages><ol><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/design-phase/>design-phase (7)</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/preprocessing/>preprocessing (9)</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/learning/>learning (9)</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/evaluation/>evaluation (6)</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/prediction/>prediction (3)</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/post-hoc/>post-hoc (15)</a></li></ol></div><h2><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/>Tools</a></h2><div class=tools><ul><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/aequitas/>Aequitas: Bias and Fairness Audit Toolkit</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/agile_ethics_for_ai/>Agile Ethics for AI</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/algorithmwatch/>AI Ethics Guidelines Global Inventory</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/algorithmic-accountability-policy-toolkit/>Algorithmic Accountability Policy Toolkit</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/art/>ART: Adversial Robustness 360 Toolbox</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/data-ethics-canvas/>Data Ethics Canvas</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/datasheet/>Datasheets for Datasets</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/debiaswe/>Debiaswe: try to make word embeddings less sexist</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/deda/>DEDA: De Ethische Data Assistent</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/dice/>DiCE: Diverse Counterfactual Explanations</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/equity-evaluation-corpus/>Equity Evaluation Corpus (EEC)</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/factsheets/>FactSheets: Increasing Trust in AI Services through Supplier's Declaration of Conformity</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/fairlearn/>Fairlearn</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/fairness-tree/>Fairness Decision Tree</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/h2o-mli-resources/>H2O MLI Resources</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/ibm-ai-fairness-360/>IBM AI Fairness 360</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/interpret-text/>Interpret-Text</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/interpretml/>InterpretML</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/lime/>LIME: Local Interpretable Model-agnostic Explanations</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/model-card/>Model cards for Model Reporting</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/shap/>SHAP: SHapley Additive exPlanations</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/smactr/>SMACTR: End-to-End Framework for Internal Algorithmic Auditing</a></li></ul></div></main><footer>Last modified on 21-06-2021.<p>&copy; 2021 <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p></footer></body></html>