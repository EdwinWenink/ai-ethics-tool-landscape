<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.85.0"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><link rel="shortcut icon" href=img/favicon.ico><title>Ethical AI Tool Landscape</title><link rel=stylesheet href=https://edwinwenink.github.io/ai-ethics-tool-landscape/css/style.css><link rel=alternate type=application/rss+xml href=https://edwinwenink.github.io/ai-ethics-tool-landscape/index.xml title="Ethical AI Tool Landscape"></head><body><header><div class=inline-block><a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape target=_blank><img src=https://edwinwenink.github.io/ai-ethics-tool-landscape/img/GitHub-Mark/PNG/GitHub-Mark-32px.png alt="Github page" class=inline-logo></a></div><nav><div id=breadcrumbs><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Home</a>
| <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape//taxonomy>Taxonomy</a></div></nav></header><main><h1 class=title>AI Ethics Tool Landscape</h1><p>This <b>open source</b> and <b>plain-text</b> project provides a <b>taxonomy</b> for the existing <b>tool landscape</b> for <b>ethical</b> and <b>trustworthy</b> Artificial Intelligence (<b>AI</b>).</p><p>You can find tools using high-level concepts, such as the <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/>value</a> they support, or the <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/>project stage</a> in which a tool is applicable.
But you can use many fine-grained distinctions as well.
For example, you can distinguish tools based on the <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tasks/>machine learning tasks</a>, the <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/data/>data type</a> or the <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/languages/>programming languages</a> they support.
Explainability tools output various <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/>types of explanation</a> and fairness tools may assume different <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/fairness/>types of fairness</a>.
Some tools are <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/categories/model-agnostic>model-agnostic</a> whereas others can only be used in combination with <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/categories/model-specific>specific types of models</a>.
For more an overview of all taxonomy terms, visit the <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/taxonomy/>taxonomy</a> page.</p><p>See the <a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape target=_blank>project page</a> on how to <b>contribute</b> to this project.</p><h2><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/>Values</a></h2><div class=values><ul><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/accountability/>Accountability</a> (11)</li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/explainability/>Explainability</a> (17)</li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/fairness/>Fairness</a> (14)</li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/privacy/>Privacy</a> (4)</li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/security/>Security</a> (3)</li></ul></div><h2><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/>Stages</a></h2><div class=stages><ol><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/design-phase/>Design phase (10)</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/preprocessing/>Preprocessing (13)</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/in-processing/>In-processing (17)</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/post-processing/>Post-processing (25)</a></li></ol></div><h2><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/>Tools</a></h2><div class=tools><ul><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/aequitas/>Aequitas: Bias and Fairness Audit Toolkit</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/agile-ethics-for-ai/>Agile Ethics for AI</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/algorithmwatch/>AI Ethics Guidelines Global Inventory</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/algorithmic-accountability-policy-toolkit/>Algorithmic Accountability Policy Toolkit</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/alibi/>Alibi</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/alibi-detect/>Alibi Detect</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/art/>ART: Adversial Robustness 360 Toolbox</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/captum/>Captum</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/cem/>Contrastive Explanation Method (CEM)</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/data-ethics-canvas/>Data Ethics Canvas</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/data-nutrition-label/>Data Nutrition Label</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/data-statements-for-nlp/>Data Statements for NLP</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/datasheet/>Datasheets for Datasets</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/debiaswe/>Debiaswe: try to make word embeddings less sexist</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/deda/>DEDA: De Ethische Data Assistent</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/deepexplain/>DeepExplain</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/deeplift/>DeepLIFT</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/dice/>DiCE: Diverse Counterfactual Explanations</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/eli5/>ELI5</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/equity-evaluation-corpus/>Equity Evaluation Corpus (EEC)</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/factsheets/>FactSheets: Increasing Trust in AI Services through Supplier's Declaration of Conformity</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/fairlearn/>Fairlearn</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/fairness-tree/>Fairness Decision Tree</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/fairness-in-classification/>Fairness in Classification</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/h2o-mli-resources/>H2O MLI Resources</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/ibm-ai-fairness-360/>IBM AI Fairness 360</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/interpret-text/>Interpret-Text</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/interpretml/>InterpretML</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/lime/>LIME: Local Interpretable Model-agnostic Explanations</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/model-card/>Model cards for Model Reporting</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/openmined/>OpenMined (PySyft)</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/shap/>SHAP: SHapley Additive exPlanations</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/smactr/>SMACTR: End-to-End Framework for Internal Algorithmic Auditing</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/tensorflow-privacy/>TensorFlow Privacy</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/treeinterpreter/>TreeInterpreter</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/what-if-tool/>What-If Tool</a></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/xai-toolbox/>XAI Toolbox</a></li></ul></div></main><footer><p>Last modified on 19-07-2021.</p><p>&copy; 2021 <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p></footer></body></html>