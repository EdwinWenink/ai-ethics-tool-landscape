<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>H2O MLI Resources</title><link rel=stylesheet href=https://edwinwenink.github.io/ai-ethics-tool-landscape/css/style.css></head><body><header><div class=inline-block><a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape target=_blank><img src=https://edwinwenink.github.io/ai-ethics-tool-landscape/img/GitHub-Mark/PNG/GitHub-Mark-32px.png alt="Github page" class=inline-logo></a></div><nav><div id=breadcrumbs><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Home</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools>Tools</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/h2o-mli-resources/>H2o mli resources</a>
| <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape//taxonomy>Taxonomy</a></div></nav></header><main><article><h1 class=title>H2O MLI Resources</h1><div><ul><li id=values>Values: {
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/explainability>explainability</a>
}<ul><li>Explanation type: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/local-surrogate>local surrogate</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/global-surrogate>global surrogate</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/partial-dependence-plot>partial dependence plot</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/ice-plot>ICE plot</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/shapley-value>shapley value</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/sensitivity-analysis>sensitivity analysis</a> }</li></ul></li><li id=categories>Categories: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/categories/model-agnostic>model-agnostic</a> }</li><li id=design-phase>Stage: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/learning>learning</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/post-hoc>post-hoc</a> }</li><li id=repository>Repository: <a href=https://github.com/h2oai/mli-resources target=_blank>https://github.com/h2oai/mli-resources</a></li><li id=model>Tasks: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tasks/classification>classification</a> }</li><li id=model>Input data: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/data/tabular>tabular</a> }</li><li id=languages>Languages: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/languages/python>Python</a> }</li><li id=references>References:<ul><li><a href=https://www.h2o.ai/ target=_blank>H2O.ai</a></li></ul><ul><li><a href=https://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/index.html target=_blank>H2O documentation (Python)</a></li></ul></li></ul></div><hr><div><p>This repository by H2O.ai contains useful resources and notebooks that showcase well-known machine learning interpretability techniques.
The examples use the <code>h2o</code> Python package with their own estimators (e.g. their own fork of XGBoost), but all code is open-source and the examples are still illustrative of the interpretability techniques.
These case studies that also deal with practical coding issues and preprocessing steps, e.g. that LIME can be unstable when there are strong correlations between input variables.
In particular, there are helpful examples for:</p><ul><li>Global Surrogate Models (example with Decision Tree Surrogate) <a href=https://github.com/h2oai/mli-resources/blob/master/notebooks/dt_surrogate.ipynb>[notebook]</a></li><li>XGBoost with monotonic constraints <a href=https://github.com/h2oai/mli-resources/blob/master/notebooks/mono_xgboost.ipynb>[notebook]</a></li><li>Local Interpretable Model Agnostic Explanations (LIME) <a href=https://github.com/h2oai/mli-resources/blob/master/notebooks/lime.ipynb>[notebook]</a><ul><li>cf.
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/lime/>LIME</a></li></ul></li><li>Local Feature Importance and Reason Codes using LOCO <a href=https://github.com/h2oai/mli-resources/blob/master/notebooks/loco.ipynb>[notebook]</a></li><li>Partial Dependence and ICE Plots <a href=https://github.com/h2oai/mli-resources/blob/master/notebooks/pdp_ice.ipynb>[notebook]</a></li><li>Sensitivity Analysis <a href=https://github.com/h2oai/mli-resources/blob/master/notebooks/sensitivity_analysis.ipynb>[notebook]</a></li></ul><p>There is no license provided in the repository, just a request to cite original paper authors and the H20.ai machine learning interpretability team where appropriate.</p><p>The repository also contains the following interpretability cheatsheet:</p><p><img src=https://raw.githubusercontent.com/h2oai/mli-resources/master/cheatsheet.png alt=Cheatsheet></p></div></article></main><footer><p>Last modified on 21-06-2021.</p><p>&copy; 2021 <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p></footer></body></html>