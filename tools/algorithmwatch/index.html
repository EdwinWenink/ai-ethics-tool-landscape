<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><link rel="shortcut icon" href=img/favicon.ico><title>AI Ethics Guidelines Global Inventory</title><link rel=stylesheet href=https://edwinwenink.github.io/ai-ethics-tool-landscape/css/style.css></head><body><header><div class=inline-block><a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape target=_blank><img src=https://edwinwenink.github.io/ai-ethics-tool-landscape/img/GitHub-Mark/PNG/GitHub-Mark-32px.png alt="Github page" class=inline-logo></a></div><nav><div id=breadcrumbs><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Home</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools>Tools</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/algorithmwatch/>Algorithmwatch</a>
| <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape//taxonomy>Taxonomy</a></div></nav></header><main><article><h1 class=title>AI Ethics Guidelines Global Inventory</h1><div><ul><li id=values>Values: {
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/accountability>accountability</a>
}</li><li id=categories>Categories: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/categories/model-agnostic>model-agnostic</a> }</li><li id=design-phase>Stage: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/design-phase>design-phase</a> }</li><li id=references>References:<ul><li><a href=https://inventory.algorithmwatch.org/ target=_blank>Algorithm Watch inventory</a></li></ul></li></ul></div><hr><div><p>AlgorithmWatch is maintaining a searchable inventory of published frameworks that set out ethical AI values.
They can be searched on sector/actor, type, region and location.</p><p>AlgorithmWatch noted some common patterns <a href=https://algorithmwatch.org/en/ai-ethics-guidelines-global-inventory/>here</a> after publishing the first version of the index:</p><ul><li>&ldquo;All include the similar principles on transparency, equality/non-discrimination, accountability and safety. Some add additional principles, such as the demand for AI be socially beneficial and protect human rights.&rdquo;</li><li>&ldquo;Most frameworks are developed by coalitions, or institutions such as universities that then invite companies and individuals to sign up to these.&rdquo;</li><li>&ldquo;Only a few companies have developed their own frameworks.&rdquo;</li><li>&ldquo;Almost all examples are voluntary commitments. There are only three or four examples that indicate an oversight or enforcement mechanism.&rdquo;</li><li>&ldquo;Apart from around 10 documents, all were published in 2018 or 2019 (some did not have a date).&rdquo;</li><li>&ldquo;Overwhelmingly, the declarations take the form of statements, e.g. “we will ensure our data sets are not biased”. Few include recommendations or examples of how to operationalise the principles.&rdquo;</li></ul><p>At the moment of writing, a total of 167 frameworks are indexed, of which only 8 are binding agreements.
This shows that the main challenges of AI ethics principles is to 1) operationalise them and 2) make them sufficiently binding so as to avoid allegations of ethics &ldquo;whitewashing&rdquo;.</p></div></article></main><footer><p>Last modified on 21-06-2021.</p><p>&copy; 2021 <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p></footer></body></html>