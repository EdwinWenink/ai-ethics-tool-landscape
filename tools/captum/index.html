<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><link rel="shortcut icon" href=img/favicon.ico><title>Captum</title><link rel=stylesheet href=https://edwinwenink.github.io/ai-ethics-tool-landscape/css/style.css></head><body><header><div class=inline-block><a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape target=_blank><img src=https://edwinwenink.github.io/ai-ethics-tool-landscape/img/GitHub-Mark/PNG/GitHub-Mark-32px.png alt="Github page" class=inline-logo></a></div><nav><div id=breadcrumbs><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Home</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools>Tools</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/captum/>Captum</a>
| <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape//taxonomy>Taxonomy</a></div></nav></header><main><article><h1 class=title>Captum</h1><div><ul><li id=values>Values: {
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/explainability>explainability</a>
}<ul><li>Explanation type: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/gradient-based>gradient-based</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/shapley-value>Shapley value</a> }</li></ul></li><li id=categories>Categories: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/categories/model-specific>model-specific</a> }</li><li id=design-phase>Stage: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/in-processing>in-processing</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/post-processing>post-processing</a> }</li><li id=repository>Repository: <a href=https://github.com/pytorch/captum target=_blank>https://github.com/pytorch/captum</a></li><li id=model>Tasks: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tasks/classification>classification</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tasks/segmentation>segmentation</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tasks/regression>regression</a> }</li><li id=model>Input data: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/data/tabular>tabular</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/data/image>image</a> }</li><li id=licence>Licence: BSD-3</li><li id=languages>Languages: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/languages/python>Python</a> }</li><li id=framework>Frameworks: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/frameworks/pytorch>PyTorch</a> }</li><li id=references>References:<ul><li><a href=https://captum.ai/docs/algorithms_comparison_matrix target=_blank>captum.ai</a></li></ul></li></ul></div><hr><div><p>Captum is a model interpretability library specifically <code>PyTorch</code>.
It is actively maintained at the moment of writing and supports an extensive array of interpretability methods.</p><p>The Captum website also offers a large range of <a href=https://captum.ai/tutorials/>hands-on tutorials</a> for various use cases.</p><h2 id=supported-interpretability-methods>Supported interpretability methods</h2><p><code>Captum</code> supports a very extensive list of interpretability algorithms.
All paper references for each of the supported methods are <a href=https://github.com/pytorch/captum#references-of-algorithms>listed in the README</a>, so they will not be repeated here.</p><p>Have a look at this nice <a href=https://captum.ai/docs/algorithms_comparison_matrix>algorithms comparison matrix</a> offered on the <a href=captum.ai>captum.ai</a> website.
All supported algorithms are <a href=https://captum.ai/docs/algorithms>described here</a>.</p><p>It is good to note that many of these algorithms have multiple variants, as also explained in the <a href=https://captum.ai/docs/algorithms>algorithm explanations</a>:</p><ul><li>Primary Attribution: Evaluates contribution of each input feature to the output of a model.</li><li>Layer Attribution: Evaluates contribution of each neuron in a given layer to the output of the model.</li><li>Neuron Attribution: Evaluates contribution of each input feature on the activation of a particular hidden neuron.</li></ul><p>A nice touch is that some methods provide a &ldquo;convergence delta&rdquo; argument which quantifies the approximation error for a single input sample.</p><p>Supported interpretability algorithms:</p><ul><li><code>IntegratedGradients</code>, <code>LayerIntegratedGardients</code></li><li><code>InputXGradient</code></li><li><code>SmoothGrad</code></li><li><code>NoiseTunnel</code></li><li><code>NeuronConductance</code></li><li><code>LayerConductance</code></li><li><code>DeepLift</code>, <code>NeuronDeepLift</code>, <code>LayerDeepLift</code></li><li><code>NeuronIntegratedGradients</code></li><li><code>GradientShap</code>, <code>NeuronGradientShap</code>, <code>LayerGradientShap</code>, <code>DeepLiftShap</code>, <code>NeuronDeepLiftShap</code>, <code>LayerDeepLiftShap</code></li><li><code>InternalInfluence</code></li><li><code>Saliency</code>, <code>NeuronGradient</code></li><li><code>GradCAM</code>, <code>Guided GradCAM</code></li><li><code>Deconvolution</code>, <code>Neuron Deconvolution</code></li><li><code>Guided Backpropagation</code>, <code>Neuron Guided Backpropagation</code></li><li><code>Feature Permutation</code></li><li><code>Occlusion</code></li><li><code>Shapley Value</code></li><li><code>Infidelity and Sensitivity</code></li></ul><h2 id=insights-interface>Insights interface</h2><p>A nice web interface is also provided to apply and visualize the offered interpretability algorithms.
For an example, run:</p><pre><code>python -m captum.insights.example
</code></pre><p><code>Insights</code> requires <code>Node >= 8x</code> and <code>Yarn >= 1.5</code>.</p></div></article></main><footer><p>Last modified on 13-07-2021.</p><p>&copy; 2021 <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p></footer></body></html>