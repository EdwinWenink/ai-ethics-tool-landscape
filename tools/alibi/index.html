<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Alibi</title><link rel=stylesheet href=https://edwinwenink.github.io/ai-ethics-tool-landscape/css/style.css></head><body><header><div class=inline-block><a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape target=_blank><img src=https://edwinwenink.github.io/ai-ethics-tool-landscape/img/GitHub-Mark/PNG/GitHub-Mark-32px.png alt="Github page" class=inline-logo></a></div><nav><div id=breadcrumbs><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Home</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools>Tools</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/alibi>Alibi</a>
| <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape//taxonomy>Taxonomy</a></div></nav></header><main><article><h1 class=title>Alibi</h1><div><ul><li id=values>Values: {
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/explainability>explainability</a>
}<ul><li>Explanation type: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/global-surrogate>global surrogate</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/local-surrogate>local surrogate</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/example-based>example-based</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/shapley-value>Shapley value</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/anchor>anchor</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/contrastive>contrastive</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/counterfactual>counterfactual</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/ale>ALE</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/gradient-based>gradient-based</a> }</li></ul></li><li id=categories>Categories: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/categories/model-specific>model-specific</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/categories/model-agnostic>model-agnostic</a> }</li><li id=design-phase>Stage: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/post-hoc>post-hoc</a> }</li><li id=repository>Repository: <a href=https://github.com/SeldonIO/alibi target=_blank>https://github.com/SeldonIO/alibi</a></li><li id=model>Tasks: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tasks/classification>classification</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tasks/regression>regression</a> }</li><li id=model>Input data: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/data/image>image</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/data/text>text</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/data/tabular>tabular</a> }</li><li id=licence>Licence: Apache License 2.0</li><li id=languages>Languages: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/languages/python>Python</a> }</li></ul></div><hr><div><p>Alibi is an open-source Python library that supports various interpretability techniques and a broad array of explanation types.
The README already provides an overview of the supported methods and when they are applicable.
The following table with supported methods is copied from the <a href=https://github.com/SeldonIO/alibi/blob/master/README.md>README</a> (slightly abbreviated):</p><h3 id=supported-methods>Supported methods</h3><table><thead><tr><th style=text-align:left>Method</th><th style=text-align:left>Models</th><th style=text-align:center>Explanations</th><th style=text-align:center>Classification</th><th style=text-align:center>Regression</th><th style=text-align:center>Tabular</th><th style=text-align:center>Text</th><th style=text-align:center>Images</th><th style=text-align:center>Categorical features</th></tr></thead><tbody><tr><td style=text-align:left><a href=https://docs.seldon.io/projects/alibi/en/latest/methods/ALE.html>ALE</a></td><td style=text-align:left>BB</td><td style=text-align:center>global</td><td style=text-align:center>✔</td><td style=text-align:center>✔</td><td style=text-align:center>✔</td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td></tr><tr><td style=text-align:left><a href=https://docs.seldon.io/projects/alibi/en/latest/methods/Anchors.html>Anchors</a></td><td style=text-align:left>BB</td><td style=text-align:center>local</td><td style=text-align:center>✔</td><td style=text-align:center></td><td style=text-align:center>✔</td><td style=text-align:center>✔</td><td style=text-align:center>✔</td><td style=text-align:center>✔</td></tr><tr><td style=text-align:left><a href=https://docs.seldon.io/projects/alibi/en/latest/methods/CEM.html>CEM</a></td><td style=text-align:left>BB* TF/Keras</td><td style=text-align:center>local</td><td style=text-align:center>✔</td><td style=text-align:center></td><td style=text-align:center>✔</td><td style=text-align:center></td><td style=text-align:center>✔</td><td></td></tr><tr><td style=text-align:left><a href=https://docs.seldon.io/projects/alibi/en/latest/methods/CF.html>Counterfactuals</a></td><td style=text-align:left>BB* TF/Keras</td><td style=text-align:center>local</td><td style=text-align:center>✔</td><td style=text-align:center></td><td style=text-align:center>✔</td><td style=text-align:center></td><td style=text-align:center>✔</td><td style=text-align:center></td></tr><tr><td style=text-align:left><a href=https://docs.seldon.io/projects/alibi/en/latest/methods/CFProto.html>Prototype Counterfactuals</a></td><td style=text-align:left>BB* TF/Keras</td><td style=text-align:center>local</td><td style=text-align:center>✔</td><td style=text-align:center></td><td style=text-align:center>✔</td><td style=text-align:center></td><td style=text-align:center>✔</td><td style=text-align:center>✔</td></tr><tr><td style=text-align:left><a href=https://docs.seldon.io/projects/alibi/en/latest/methods/IntegratedGradients.html>Integrated Gradients</a></td><td style=text-align:left>TF/Keras</td><td style=text-align:center>local</td><td style=text-align:center>✔</td><td style=text-align:center>✔</td><td style=text-align:center>✔</td><td style=text-align:center>✔</td><td style=text-align:center>✔</td><td style=text-align:center>✔</td></tr><tr><td style=text-align:left><a href=https://docs.seldon.io/projects/alibi/en/latest/methods/KernelSHAP.html>Kernel SHAP</a></td><td style=text-align:left>BB</td><td style=text-align:center>local global</td><td style=text-align:center>✔</td><td style=text-align:center>✔</td><td style=text-align:center>✔</td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center>✔</td></tr><tr><td style=text-align:left><a href=https://docs.seldon.io/projects/alibi/en/latest/methods/TreeSHAP.html>Tree SHAP</a></td><td style=text-align:left>WB</td><td style=text-align:center>local global</td><td style=text-align:center>✔</td><td style=text-align:center>✔</td><td style=text-align:center>✔</td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center>✔</td></tr></tbody></table><p>The README also explains the keys:</p><ul><li>BB - black-box (only require a prediction function)</li><li>BB* - black-box but assume model is differentiable</li><li>WB - requires white-box model access. There may be limitations on models supported</li><li>TF/Keras - TensorFlow models via the Keras API</li><li>Local - instance specific explanation, why was this prediction made?</li><li>Global - explains the model with respect to a set of instances</li></ul><p>For more detailed information on the supported methods, see the <a href=https://docs.seldon.io/projects/alibi/en/latest/overview/algorithms.html>algorithm overview</a>.</p></div></article></main><footer><p>Last modified on 30-06-2021.</p><p>&copy; 2021 <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p></footer></body></html>