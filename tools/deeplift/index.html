<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>DeepLIFT</title><link rel=stylesheet href=https://edwinwenink.github.io/ai-ethics-tool-landscape/css/style.css></head><body><header><div class=inline-block><a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape target=_blank><img src=https://edwinwenink.github.io/ai-ethics-tool-landscape/img/GitHub-Mark/PNG/GitHub-Mark-32px.png alt="Github page" class=inline-logo></a></div><nav><div id=breadcrumbs><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Home</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools>Tools</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/deeplift/>Deeplift</a>
| <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape//taxonomy>Taxonomy</a></div></nav></header><main><article><h1 class=title>DeepLIFT</h1><div><ul><li id=values>Values: {
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/explainability>explainability</a>
}<ul><li>Explanation type: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/gradient-based>gradient-based</a> }</li></ul></li><li id=categories>Categories: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/categories/model-specific>model-specific</a> }</li><li id=design-phase>Stage: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/in-processing>in-processing</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/post-processing>post-processing</a> }</li><li id=repository>Repository: <a href=https://github.com/kundajelab/deeplift target=_blank>https://github.com/kundajelab/deeplift</a></li><li id=model>Tasks: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tasks/classification>classification</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tasks/segmentation>segmentation</a> }</li><li id=model>Input data: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/data/image>image</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/data/text>text</a> }</li><li id=licence>Licence: MIT</li><li id=references>References:<ul><li><a href=https://arxiv.org/abs/1704.02685 target=_blank>Shrikumar et al. - Learning Important Features Through Propagating Activation Differences</a></li></ul><ul><li><a href=https://arxiv.org/abs/1412.6806 target=_blank>Springenberg et al. - Striving for Simplicity: The All Convolutional Net</a></li></ul><ul><li><a href=https://arxiv.org/abs/1611.02639 target=_blank>Sundararajan et al. - Gradients of Counterfactuals</a></li></ul><ul><li><a href=https://arxiv.org/abs/1703.01365 target=_blank>Sundararajan et al. - Axiomatic Attribution for Deep Networks</a></li></ul></li></ul></div><hr><div><p>A brief explanation of the
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/gradient-based/>gradient-based</a>
interpretability method called DeepLIFT is given by Shrikumar et al. in the abstract of the linked paper:</p><blockquote><p>DeepLIFT (Deep Learning Important FeaTures), a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input. DeepLIFT compares the activation of each neuron to its &lsquo;reference activation&rsquo; and assigns contribution scores according to the difference. By optionally giving separate consideration to positive and negative contributions, DeepLIFT can also reveal dependencies which are missed by other approaches. Scores can be computed efficiently in a single backward pass.</p></blockquote><p>The linked repository implements the functionality explained in this paper.
Other
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/gradient-based/>gradient-based</a>
interpretation methods are also implemented, including:</p><ul><li>gradient * input (equivalent to Layerwise Relevance Propagation in networks using ReLU; see Shrikumar et al. )</li><li>guided backprop (see Springenberg et al.)</li><li>integrated gradients ( see the two papers from Sundararajan et al. )</li></ul><p>DeepLIFT is
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/categories/model-specific/>model-specific</a>
because it is designed specifically for deep neural networks, more specifically <code>Keras</code> and <code>TensorFlow</code> models.</p><p>The first step to applying <code>DeepLIFT</code> is to construct a new layer for each layer in the original neural network and specify it&rsquo;s inputs, thereby creating a network that will return importances.
For <code>Keras</code> (2.0) models, there is autoconversion functionality as illustrated in the quickstart of the README.</p><p>Note that because these layers are extra, existing gradient operators are not overridden.
The application of <code>DeepLIFT</code> should thus not affect the predictions of the original network.</p><p>A 15-min introduction to DeepLIFT can be found <a href=https://vimeo.com/238275076>here</a>:</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://player.vimeo.com/video/238275076 style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="vimeo video" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div><p>A more extended tutorial can be found <a href="https://www.youtube.com/playlist?list=PLJLjQOkqSRTP3cLB2cOOi_bQFw6KPGKML">here</a>.</p><h2 id=other-implementations>Other implementations</h2><p>The <code>DeepLIFT</code> package does not support all model types, because not all layers have a <code>DeepLIFT</code> equivalent.
In the FAQ the author explains that other packages that directly override gradient operators instead support a broader array of architectures.
Variants of <code>DeepLIFT</code> are also implemented in other packages.</p><ul><li>The
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/shap/>SHAP</a>
package includes a <code>DeepExplainer</code> that extends <code>DeepLIFT</code> with the concept of Shapley values. In addition to <code>TensorFlow</code> and <code>Keras</code> models, this implementation has <em>preliminary PyTorch</em> support at the moment of writing.</li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/deepexplain/>DeepExplain</a>
also connects DeepLIFT with Shapley values, and is actually the basis of <code>SHAP</code>&rsquo;s <code>DeepExplainer</code></li><li><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/captum/>Captum</a>
has a <code>DeepLIFT</code> implementation for <code>PyTorch</code>.</li></ul><p>The <a href=https://github.com/kundajelab/deeplift#faq>FAQ</a> contains an in-depth discussion of differences in functionality between these <code>DeepLIFT</code> implementations.</p></div></article></main><footer><p>Last modified on 13-07-2021.</p><p>&copy; 2021 <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p></footer></body></html>