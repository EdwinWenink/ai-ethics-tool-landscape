<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Datasheets for Datasets</title><link rel=stylesheet href=https://edwinwenink.github.io/ai-ethics-tool-landscape/css/style.css></head><body><header><div class=inline-block><a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape target=_blank><img src=https://edwinwenink.github.io/ai-ethics-tool-landscape/img/GitHub-Mark/PNG/GitHub-Mark-32px.png alt="Github page" class=inline-logo></a></div><nav><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/>Values</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/>Stages</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/taxonomy/>Taxonomy</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/>Tools</a></nav></header><main><article><h1 class=title>Datasheets for Datasets</h1><div><ul><li id=values>Values: {
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/accountability>accountability</a>
}</li><li id=categories>Categories: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/categories/model-agnostic>model-agnostic</a> }</li><li id=design-phase>Stage: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/design-phase>design phase</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/preprocessing>preprocessing</a> }</li><li id=references>References:<ul><li><a href=https://arxiv.org/abs/1803.09010v7 target=_blank>Gebru et al. - Datasheets for Datasets</a></li></ul></li></ul></div><hr><div><p>The method described in this paper aids in documenting datasets to help avoid unwanted consequences of data usage.</p><p>Abstract:</p><blockquote><p>The machine learning community currently has no standardized process for documenting datasets, which can lead to severe consequences in high-stakes domains. To address this gap, we propose datasheets for datasets. In the electronics industry, every component, no matter how simple or complex, is accompanied with a datasheet that describes its operating characteristics, test results, recommended uses, and other information. By analogy, we propose that every dataset be accompanied with a datasheet that documents its motivation, composition, collection process, recommended uses, and so on. Datasheets for datasets will facilitate better communication between dataset creators and dataset consumers, and encourage the machine learning community to prioritize transparency and accountability.</p></blockquote><p>The paper provides several questions and workflows to help describe the</p><ol><li>motivation</li><li>composition</li><li>collection process</li><li>preprocessing</li><li>use cases</li><li>distribution</li><li>maintenance &mldr;</li></ol><p>&mldr; of the dataset.</p><p>A
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/model-card/>model card</a>
is a similar idea but then applied to machine learning models.</p></div></article></main><footer>Last modified on 21-05-2021.<p>&copy; 2021 <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p></footer></body></html>