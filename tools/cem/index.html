<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Contrastive Explanation Method (CEM)</title><link rel=stylesheet href=https://edwinwenink.github.io/ai-ethics-tool-landscape/css/style.css></head><body><header><div class=inline-block><a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape target=_blank><img src=https://edwinwenink.github.io/ai-ethics-tool-landscape/img/GitHub-Mark/PNG/GitHub-Mark-32px.png alt="Github page" class=inline-logo></a></div><nav><div id=breadcrumbs><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Home</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools>Tools</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/cem>Cem</a>
| <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape//taxonomy>Taxonomy</a></div></nav></header><main><article><h1 class=title>Contrastive Explanation Method (CEM)</h1><div><ul><li id=values>Values: {
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/explainability>explainability</a>
}<ul><li>Explanation type: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/contrastive>contrastive</a> }</li></ul></li><li id=categories>Categories: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/categories/model-agnostic>model-agnostic</a> }</li><li id=design-phase>Stage: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/post-hoc>post-hoc</a> }</li><li id=repository>Repository: <a href=https://github.com/IBM/Contrastive-Explanation-Method target=_blank>https://github.com/IBM/Contrastive-Explanation-Method</a></li><li id=model>Tasks: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tasks/classification>classification</a> }</li><li id=model>Input data: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/data/image>image</a> }</li><li id=licence>Licence: Apache License 2.0</li><li id=languages>Languages: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/languages/python>Python</a> }</li><li id=references>References:<ul><li><a href=https://arxiv.org/abs/1802.07623 target=_blank>Dhurandhar et al. - Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives</a></li></ul></li></ul></div><hr><div><p>Dhurandhar et al. support a type of
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/contrastive/>contrastive</a>
explanation based on what they call <em>pertinent negatives</em>.
A contrastive explanation answers the question: &ldquo;Why P, rather than Q&rdquo;?</p><p>CEM supports such an explanation by finding the minimal set of features that lead to prediction P (a <em>pertinent positive</em> that resembles an
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/anchor/>anchor</a>
explanation), and additionally a minimal set of features that should be <em>absent</em> to maintain decision P instead of the decision for closest class Q (a <em>pertinent negative</em> that is somewhat similar to a
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/counterfactual/>counterfactual</a>
).</p><p>CEM is also implemented in the more encompassing
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/alibi/>Alibi</a>
.</p></div></article></main><footer><p>Last modified on 30-06-2021.</p><p>&copy; 2021 <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p></footer></body></html>