<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><link rel="shortcut icon" href=img/favicon.ico><title>OpenMined (PySyft)</title><link rel=stylesheet href=https://edwinwenink.github.io/ai-ethics-tool-landscape/css/style.css></head><body><header><div class=inline-block><a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape target=_blank><img src=https://edwinwenink.github.io/ai-ethics-tool-landscape/img/GitHub-Mark/PNG/GitHub-Mark-32px.png alt="Github page" class=inline-logo></a></div><nav><div id=breadcrumbs><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Home</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools>Tools</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/openmined/>Openmined</a>
| <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape//taxonomy>Taxonomy</a></div></nav></header><main><article><h1 class=title>OpenMined (PySyft)</h1><div><ul><li id=values>Values: {
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/privacy>privacy</a>
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/security>security</a>
}</li><li id=categories>Categories: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/categories/model-specific>model-specific</a> }</li><li id=design-phase>Stage: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/in-processing>in-processing</a> }</li><li id=repository>Repository: <a href=https://github.com/OpenMined target=_blank>https://github.com/OpenMined</a></li><li id=model>Tasks: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tasks/classification>classification</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tasks/regression>regression</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tasks/nlp>NLP</a> }</li><li id=model>Input data: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/data/tabular>tabular</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/data/image>image</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/data/text>text</a> }</li><li id=licence>Licence: Apache License 2.0</li><li id=languages>Languages: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/languages/python>Python</a> }</li><li id=framework>Frameworks: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/frameworks/tensorflow>TensorFlow</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/frameworks/keras>Keras</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/frameworks/pytorch>PyTorch</a> }</li><li id=references>References:<ul><li><a href=https://www.openmined.org/ target=_blank>OpenMined</a></li></ul><ul><li><a href=https://www.youtube.com/c/OpenMinedOrg target=_blank>Video resources</a></li></ul></li></ul></div><hr><div><p>The OpenMined community is a collaboration of several organizations, including TensorFlow, PyTorch and Keras, to create an open-source ecosystem of privacy tools that extend libraries such as PyTorch with cryptographic techniques and differential privacy.
The aim is to contribute to the adaptation of <em>privacy-preserving AI</em>.</p><p>To this end, OpenMined offers several privacy-preserving tools on their <a href=https://github.com/OpenMined>github</a>.
A main tool is <a href=https://github.com/OpenMined/PySyft>PySyft</a>, which allows &ldquo;computing on data you do not own and cannot see&rdquo;.</p><p>The <a href=https://www.openmined.org/>main website of OpenMined</a> categorizes their efforts towards private AI as such:</p><ul><li><strong>Remote execution</strong>: Extensions to PyTorch and Tensorflow to support execution on remote machines you don&rsquo;t have access to<ul><li><em>Federated learning</em>: send models to several remote machines that have (part of) the training data and train locally on them, without the need to download sensitive training data</li><li><em>On-device prediction</em>: run model inference locally on devices without the need to have the dataset e.g. in the cloud</li></ul></li><li><strong>Encrypted computation</strong>: the previous steps keeps training data secure, but it is also possible to keep computations themselves secure.<ul><li><em>Multi-party computation</em>: ensure that several parties together can train a model, but no single party can see the model contents, or use or train it by themselves.</li><li><em>Homomorphic encryption</em>: a single model owner can use homomorphic encryption to allow untrusted 3rd parties to use or train the model, without being able to steal the model.</li></ul></li><li><strong>Differential Privacy</strong>: determine the right amount of obfuscation based on how much information is leaked for example when revealing the predictions of a trained model.<ul><li>Several published techniques are provided</li><li><em>Automatic DP</em>: support for automatically determining an appropriate amount of obfuscation, based on the operations you use.</li></ul></li></ul><p>From January 2021 on, OpenMined also publishes free courses on private AI and the tools they offer.</p></div></article></main><footer><p>Last modified on 13-07-2021.</p><p>&copy; 2021 <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p></footer></body></html>