<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<link rel="shortcut icon" href=img/favicon.ico>
<title>Data Statements for NLP</title>
<link rel=stylesheet href=https://edwinwenink.github.io/ai-ethics-tool-landscape/css/style.css>
</head>
<body>
<header>
<div class=inline-block>
<a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape target=_blank><img src=https://edwinwenink.github.io/ai-ethics-tool-landscape/img/GitHub-Mark/PNG/GitHub-Mark-32px.png alt="Github page" class=inline-logo></a>
</div>
<nav>
<div id=breadcrumbs>
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Home</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools>Tools</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/data-statements-for-nlp/>Data statements for nlp</a>
| <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape//taxonomy>Taxonomy</a>
</div>
</nav>
</header>
<main>
<article>
<h1 class=title>Data Statements for NLP</h1>
<div>
<ul>
<li id=values> Values: {
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/accountability>accountability</a>
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/fairness>fairness</a>
}
</li>
<li id=categories> Categories: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/categories/model-agnostic>model-agnostic</a> } </li>
<li id=design-phase> Stage: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/design-phase>design phase</a> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/preprocessing>preprocessing</a> }</li>
<li id=model>Tasks: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tasks/nlp>NLP</a> }</li>
<li id=model>Input data: { <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/data/text>text</a> }</li>
<li id=references>References:
<ul>
<li><a href=https://www.aclweb.org/anthology/Q18-1041/ target=_blank>Bender & Friedman - Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science</a></li>
</ul>
</li>
</ul>
</div>
<hr>
<div>
<p>A data statement, according to the authors, is &mldr;</p>
<blockquote>
<p>a characterization of a dataset that provides context to allow developers and users to better understand how experimental results might generalize,how software might be appropriately deployed,and what biases might be reflected in systems built on the software. (587)</p>
</blockquote>
<p>This paper specifically focuses on ethically responsive <em>NLP</em> technology.
The authors argue that a data statement should be an integral part of work and writing on NLP.</p>
<p>Explicitly filling in a data statement are helpful for identifying emergent bias, which may emerge when a NLP model is deployed, as well as historical bias in the training data, because it helps finding potential gaps between the speaker populations that are represented in the data and the populations the NLP system will work with.
Additionally, subtleties like the annotator demographic are also explicated, because the linguistic context of annotators may also influence the performance of the system.</p>
<p>Similar efforts are the
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/datasheet/>datasheet</a>
and
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/data-nutrition-label/>data nutrition label</a>
</p>
<h2 id=data-statement-schema>Data Statement Schema</h2>
<p>Statements can be offered in short and long form.
The long form is intended for systems documentation and academic papers.
The following table summarizes the components of the long form, see p. 590-591.
The short form is essentially a prose summary of the long form that should not replace, but instead introduce and point to the long form.
For further clarifications and justifications of these categories, consult the paper.</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Content</th>
</tr>
</thead>
<tbody>
<tr>
<td>Curation Rationale</td>
<td>&ldquo;Which texts were included and what were the goals in selecting texts, both in the original collection and in any further sub-selection?&rdquo; (p. 590)</td>
</tr>
<tr>
<td>Language variety</td>
<td>Provide a language tag (from <a href=https://tools.ietf.org/rfc/bcp/bcp47.txt>BCP-47</a>) that identifies a language variety, and additional prose description of the language variety</td>
</tr>
<tr>
<td>Speaker demographic</td>
<td>Specifications of age, gender, ethnicity, native language, socioeconomic status, number of different speakers represented, presence of disordered speech</td>
</tr>
<tr>
<td>Annotator demographic</td>
<td>Specifications of age, gender, ethnicity, native language, socioeconomic status, training in linguistics or relevant discipline</td>
</tr>
<tr>
<td>Speech situation</td>
<td>Time and place, modality, scripted/edited vs spontaneous, synchronous vs. asynchronous interaction, intended audience</td>
</tr>
<tr>
<td>Text characteristics</td>
<td>Specify genre, topic and structural characteristics</td>
</tr>
<tr>
<td>Recording Quality</td>
<td>If applicable, indicatie factors impacting recording quality</td>
</tr>
<tr>
<td>Other</td>
<td>The above is not exclusive and may be appended with other relevant information</td>
</tr>
</tbody>
</table>
<h2 id=case-studies>Case studies</h2>
<p>Two case studies are provided in the article itself, so refer to the article for a concrete in-depth example.
The first case study is about hate speech Twitter annotations.
The second case study concerns a collection of video interviews <em>Voices from the Rwanda Tribunal</em>.</p>
</div>
</article>
</main>
<footer>
<p>Last modified on 24-06-2021.</p>
<p>&copy; 2021 <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p>
</footer>
</body>
</html>