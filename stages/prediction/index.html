<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>prediction</title><link rel=stylesheet href=https://edwinwenink.github.io/ai-ethics-tool-landscape/css/style.css><link rel=alternate type=application/rss+xml href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/prediction/index.xml title="Ethical AI Tool Landscape"></head><body><header><div class=inline-block><a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape target=_blank><img src=https://edwinwenink.github.io/ai-ethics-tool-landscape/img/GitHub-Mark/PNG/GitHub-Mark-32px.png alt="Github page" class=inline-logo></a></div><nav><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/>Values</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/>Stages</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/taxonomy/>Taxonomy</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/>Tools</a></nav></header><main><div><h1 class=title>prediction</h1></div><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/agile-ethics-for-ai/>Agile Ethics for AI</a></h1><div>Butnaru and others associated with the HAI center at Stanford set up a Agile Ethics workflow in the form of a Trello board. From left to right, the workflow walks you through relevant ethical considerations at the various steps of a machine learning pipeline. The phases are:
Scope Consider ethical implications of the project Consider skill mapping (what&rsquo;s the impact of AI on jobs)? Facilitates up-skilling or a change of strategy in the use of human talent Data audit Led by Chief Data Officer &ldquo;Meet and plan&rdquo; stage in Agile Helpful: Data Ethics Canvas Train Build stage in Agile Consider (tools for) transparency and fairness Analyse Benchmarks, including benchmarks related to e.
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/agile-ethics-for-ai/>Read more...</a></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/art/>ART: Adversial Robustness 360 Toolbox</a></h1><div>The Adversial Robustness Toolbox (ART) is the first comprehensive toolbox that unifies many defensive techniques for four categories of adversial attacks on machine learning models. These categories are model evasion, model poisoning, model extraction and inference (e.g. inference of sensitive attributes in the training data; or determining whether an example was part of the training data). ART supports all popular machine learning frameworks, all data types and all machine learning tasks.
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/art/>Read more...</a></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/captum/>Captum</a></h1><div>Captum is a model interpretability library specifically for the PyTorch library. It is actively maintained at the moment of writing and supports an extensive array of interpretability methods.
The Captum website also offers a large range of hands-on tutorials for various use cases.
Supported interpretability methods Captum supports a very extensive list of interpretability algorithms. All paper references for each of the supported methods are listed in the README, so they will not be repeated here.
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/captum/>Read more...</a></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/deeplift/>DeepLIFT</a></h1><div>A brief explanation of the gradient-based interpretability method called DeepLIFT is given by Shrikumar et al. in the abstract of the linked paper:
DeepLIFT (Deep Learning Important FeaTures), a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input. DeepLIFT compares the activation of each neuron to its &lsquo;reference activation&rsquo; and assigns contribution scores according to the difference.
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/deeplift/>Read more...</a></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/eli5/>ELI5</a></h1><div>ELI5 provides model-specific support for models from scikit-learn, lightning, decision tree ensembles using the xgboost, LightGBM, CatBoost libraries. ELI5 mainly provides convenient wrappers to couple the feature importance coefficients that these libraries already provide with feature names, as well as convenient ways to visualize importances, e.g. by highlighting words in a text. For Keras image classifiers an implementation of the gradient-based Grad-CAM visualizations is offered, but the TensorFlow V2 backend is not supported.
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/eli5/>Read more...</a></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/smactr/>SMACTR: End-to-End Framework for Internal Algorithmic Auditing</a></h1><div>Introduction A major downside of external auditing is that it typically only can be done after model deployment. This paper presents a methodology for internal algorithmic auditing as an integral part of the development process, end-to-end.
Those who move fast and break things, beware:
The audit process is necessarily boring, slow, meticulous and methodicalâ€”antithetical to the typical rapid development pace for AI technology. However, it is critical to slow down as algorithms continue to be deployed in increasingly high-stakes domains.
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/smactr/>Read more...</a></div></article></main><footer>Last modified on 17-05-2021.<p>&copy; 2021 <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p></footer></body></html>