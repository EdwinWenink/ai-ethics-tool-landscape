<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Accountability</title><link rel=stylesheet href=/css/style.css><link rel=alternate type=application/rss+xml href=/values/accountability/index.xml title="Ethical AI Tool Landscape"></head><body><header><div class=inline-block><a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape><img src=/img/GitHub-Mark/PNG/GitHub-Mark-32px.png alt="Github page" class=inline-logo></a></div><nav><a href=http://example.org/>Ethical AI Tool Landscape</a>
> <a href=/values/>Values</a>
> <a href=/stages/>Stages</a>
> <a href=/categories/>Categories</a>
> <a href=/tools/>Tools</a>
> <a href=/taxonomy/>Taxonomy</a></nav></header><main><div><h1 class=title>Accountability</h1><div><p>Unlike
<a href=/values/explainability/>explainability</a>
or
<a href=/values/fairness/>fairness</a>
, most available tools for accountability are not technical solutions, but rather methods describing best practices.
For the sake of simplicity tools for organizational transparency, as opposed to algorithmic interpretability, are also categorized under accountability.</p></div></div><article><h1><a href=http://example.org/tools/agile_ethics_for_ai/>Agile Ethics for AI</a></h1><div>Butnaru and others associated with the HAI center at Stanford set up a Agile Ethics workflow in the form of a Trello board. From left to right, the workflow walks you through relevant ethical considerations at the various steps of a machine learning pipeline. The phases are:
Scope Consider ethical implications of the project Consider skill mapping (what&rsquo;s the impact of AI on jobs)? Facilitates up-skilling or a change of strategy in the use of human talent Data audit Led by Chief Data Officer &ldquo;Meet and plan&rdquo; stage in Agile Helpful: Data Ethics Canvas Train Build stage in Agile Consider (tools for) transparency and fairness Analyse Benchmarks, including benchmarks related to e.
<a href=http://example.org/tools/agile_ethics_for_ai/>Read more...</a></div></article><article><h1><a href=http://example.org/tools/algorithmwatch/>AI Ethics Guidelines Global Inventory</a></h1><div>AlgorithmWatch is maintaining a searchable inventory of published frameworks that set out ethical AI values. They can be searched on sector/actor, type, region and location.
AlgorithmWatch noted some common patterns here after publishing the first version of the index:
&ldquo;All include the similar principles on transparency, equality/non-discrimination, accountability and safety. Some add additional principles, such as the demand for AI be socially beneficial and protect human rights.&rdquo; &ldquo;Most frameworks are developed by coalitions, or institutions such as universities that then invite companies and individuals to sign up to these.
<a href=http://example.org/tools/algorithmwatch/>Read more...</a></div></article><article><h1><a href=http://example.org/tools/algorithmic-accountability-policy-toolkit/>Algorithmic Accountability Policy Toolkit</a></h1><div>AI Now published the Algorithmic Accountability Policy Toolkit in 2018. It is specifically tailored towards advocates concerned with government use of algorithms. The toolkit provides a FAQ, an overview of various types of algorithms used by governments in specific application areas such as public health or criminal justice, and a comprehensive list of relevant literature.
The fact that this is a toolkit and not a paper can be seen from the very practical guidance that is offered.
<a href=http://example.org/tools/algorithmic-accountability-policy-toolkit/>Read more...</a></div></article><article><h1><a href=http://example.org/tools/data-ethics-canvas/>Data Ethics Canvas</a></h1><div>The Data Ethics Canvas is a tool developed by the Open Data Institute for providing ethical guidance to organizations doing any type of project involving data. That includes data collection, sharing, and its usage for example in machine learning applications. The tool is accompanied with a white paper and a brief practical guide for its usage.
Page 3 of the practical guide lists some recommendations that are also relevant when you do not use this tool.
<a href=http://example.org/tools/data-ethics-canvas/>Read more...</a></div></article><article><h1><a href=http://example.org/tools/datasheet/>Datasheets for Datasets</a></h1><div>The method described in this paper aids in documenting datasets to help avoid unwanted consequences of data usage.
Abstract:
The machine learning community currently has no standardized process for documenting datasets, which can lead to severe consequences in high-stakes domains. To address this gap, we propose datasheets for datasets. In the electronics industry, every component, no matter how simple or complex, is accompanied with a datasheet that describes its operating characteristics, test results, recommended uses, and other information.
<a href=http://example.org/tools/datasheet/>Read more...</a></div></article><article><h1><a href=http://example.org/tools/deda/>DEDA: De Ethische Data Assistent</a></h1><div>This toolkit developed by the Utrecht Data School supports data analysts, projectmanagers, and policy makers in identifying ethical values and issues in data projects and promoting accountability towards stakeholders. The toolkit is written in Dutch and includes a poster to support brainstorm sessions, an interactive survey, and an accompanying guide with further explanations. On the toolkit&rsquo;s website you can also find several case studies that highlight ethical issues in data projects, as well as a version of the toolkit specifically for researchers.
<a href=http://example.org/tools/deda/>Read more...</a></div></article><article><h1><a href=http://example.org/tools/model-card/>Model cards for Model Reporting</a></h1><div>Model cards are an extension of the datasheet to machine learning models.
Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type [15]) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains.
<a href=http://example.org/tools/model-card/>Read more...</a></div></article><article><h1><a href=http://example.org/tools/smactr/>SMACTR: End-to-End Framework for Internal Algorithmic Auditing</a></h1><div>Introduction A major downside of external auditing is that it typically only can be done after model deployment. This paper presents a methodology for internal algorithmic auditing as an integral part of the development process, end-to-end.
Those who move fast and break things, beware:
The audit process is necessarily boring, slow, meticulous and methodicalâ€”antithetical to the typical rapid development pace for AI technology. However, it is critical to slow down as algorithms continue to be deployed in increasingly high-stakes domains.
<a href=http://example.org/tools/smactr/>Read more...</a></div></article></main><footer>Last modified on 21-05-2021.<p>&copy; 2021 <a href=http://example.org/>Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p></footer></body></html>