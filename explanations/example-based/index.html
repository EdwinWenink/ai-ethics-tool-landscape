<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>example-based</title><link rel=stylesheet href=/css/style.css><link rel=alternate type=application/rss+xml href=/explanations/example-based/index.xml title="Ethical AI Tool Landscape"></head><body><header><div class=inline-block><a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape><img src=/img/GitHub-Mark/PNG/GitHub-Mark-32px.png alt="Github page" class=inline-logo></a></div><nav><a href=http://example.org/>Ethical AI Tool Landscape</a>
> <a href=/values/>Values</a>
> <a href=/stages/>Stages</a>
> <a href=/categories/>Categories</a>
> <a href=/tools/>Tools</a>
> <a href=/taxonomy/>Taxonomy</a></nav></header><main><div><h1 class=title>example-based</h1></div><article><h1><a href=http://example.org/tools/dice/>DiCE: Diverse Counterfactual Explanations</a></h1><div>From README:
DiCE implements counterfactual (CF) explanations that provide this information by showing feature-perturbed versions of the same person who would have received the loan, e.g., you would have received the loan if your income was higher by $10,000. In other words, it provides &ldquo;what-if&rdquo; explanations for model output and can be a useful complement to other explanation methods, both for end-users and model developers.
A main innovation of DiCE is that it implements a method to make producing counter-factual examples more model-agnostic:
<a href=http://example.org/tools/dice/>Read more...</a></div></article><article><h1><a href=http://example.org/tools/interpret-text/>Interpret-Text</a></h1><div>Interpret-Text is an extension of InterpretML , specifically for several text models. Three modules are provided: ClassicalTextExplainer, UnifiedInformationExplainer and IntrospectiveRationaleExplainer.
Classical Text Explainer The ClassicalTextExplainer supports linear models from sklearn with a coefs_ call and tree-based models for which feature_importances_ is defined.
ClassicalTextExplainer includes a NLP pipeline from preprocessing to hyperparameter tuning, so it accepts raw text data as input. The default pipeline uses a unigram bag-of-words model. Elements of the pipeline can be replaced if desired.
<a href=http://example.org/tools/interpret-text/>Read more...</a></div></article></main><footer>Last modified on 31-05-2021.<p>&copy; 2021 <a href=http://example.org/>Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p></footer></body></html>