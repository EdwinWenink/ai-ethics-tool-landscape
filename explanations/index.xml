<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Explanations on Ethical AI Tool Landscape</title><link>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/</link><description>Recent content in Explanations on Ethical AI Tool Landscape</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Edwin Wenink</copyright><atom:link href="https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/index.xml" rel="self" type="application/rss+xml"/><item><title>example-based</title><link>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/example-based/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/example-based/</guid><description/></item><item><title>local surrogate</title><link>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/local-surrogate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/local-surrogate/</guid><description/></item><item><title>partial dependence plot</title><link>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/partial-dependence-plot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/partial-dependence-plot/</guid><description/></item><item><title>partial_dependence_plot</title><link>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/partial_dependence_plot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/partial_dependence_plot/</guid><description/></item><item><title>salience</title><link>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/salience/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/salience/</guid><description/></item><item><title>sensitivity analysis</title><link>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/sensitivity-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/sensitivity-analysis/</guid><description/></item><item><title>Shapley value</title><link>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/shapley-value/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/shapley-value/</guid><description/></item><item><title>white box</title><link>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/white-box/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/white-box/</guid><description/></item></channel></rss>