<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Explanations</title><link rel=stylesheet href=https://edwinwenink.github.io/ai-ethics-tool-landscape/css/style.css><link rel=alternate type=application/rss+xml href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/index.xml title="Ethical AI Tool Landscape"></head><body><header><div class=inline-block><a href=https://github.com/EdwinWenink/ai-ethics-tool-landscape target=_blank><img src=https://edwinwenink.github.io/ai-ethics-tool-landscape/img/GitHub-Mark/PNG/GitHub-Mark-32px.png alt="Github page" class=inline-logo></a></div><nav><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/values/>Values</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/stages/>Stages</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/taxonomy/>Taxonomy</a>
> <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/>Tools</a></nav></header><main><div><h1 class=title>Explanations</h1></div><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/ale/>Accumulated Local Effects (ALE)</a></h1><div>Computes feature effects (first-order) on a model for a given dataset (tabular). ALE expresses for a given feature how, on average, it influences the prediction of a model.</div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/anchor/>Anchor</a></h1><div>An &ldquo;anchor&rdquo; is a subset of features and their value ranges for which the model will almost always output the same prediction. The anchor should be as small as possible, also to promote interpretability.</div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/contrastive/>Contrastive explanations</a></h1><div>Human explanations are often contrastive, meaning that they do not answer the indeterminate &ldquo;Why?&rdquo; question, but instead &ldquo;Why P, rather than Q?&rdquo;. For example, when a mortgage application is denied, we are not interested in a very long list of tiny little details that all contributed to that decision, but we want a to-the-point explanation that shows us what we minimally have to change to get the mortgage.
For example, the CEM method supports such an explanation by finding the minimal set of features that lead to prediction P (so this looks like an anchor explanation), and additionally a minimal set of features that should be absent to maintain decision P instead of the closest class Q (which is somewhat similar to a counterfactual ).
<a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/contrastive/>Read more...</a></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/counterfactual/>counterfactual</a></h1><div></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/example-based/>example-based</a></h1><div></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/global-surrogate/>global surrogate</a></h1><div></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/gradient-based/>gradient-based</a></h1><div></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/ice-plot/>ICE plot</a></h1><div></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/local-surrogate/>local surrogate</a></h1><div></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/partial-dependence-plot/>partial dependence plot</a></h1><div></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/permutation/>permutation</a></h1><div></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/perturbation/>perturbation</a></h1><div></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/sensitivity-analysis/>sensitivity analysis</a></h1><div></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/shapley-value/>Shapley value</a></h1><div></div></article><article><h1><a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/explanations/white-box/>white box</a></h1><div></div></article></main><footer>Last modified on 30-06-2021.<p>&copy; 2021 <a href=https://edwinwenink.github.io/ai-ethics-tool-landscape/>Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p></footer></body></html>