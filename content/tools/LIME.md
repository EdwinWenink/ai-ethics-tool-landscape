---
title: LIME
values: ['explainability']
categories: ['model-agnostic']
phases: ['post-hoc']
licence: 'BSD 2-Clause "Simplified"'
repo: https://github.com/marcotcr/lime
languages: ['python']
references: 
- 'Ribeiro et al. - "Why Should I Trust You?": Explaining the Predictions of Any Classifier https://arxiv.org/abs/1602.04938'
---

"Local surrogate models are interpretable models that are used to explain individual predictions of black box machine learning models. Local interpretable model-agnostic explanations (LIME) is a paper in which the authors propose a concrete implementation of local surrogate models. Surrogate models are trained to approximate the predictions of the underlying black box model. Instead of training a global surrogate model, LIME focuses on training local surrogate models to explain individual predictions" (Molnar, 5.7)
