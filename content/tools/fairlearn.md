---
title: 'Fairlearn'
values: ['fairness']
fairness: ['group fairness']
categories: ['TODO']
tasks: ['TODO']
data: ['TODO']
stages: ['TODO']
licence: MIT
repo: https://github.com/fairlearn/fairlearn
languages: ['Python']
references: 
- 
    name: 'Fairlearn'
    url: 'https://fairlearn.org/'
---

Fairlean contains two main components:

- "[Metrics](https://fairlearn.org/main/user_guide/assessment.html) for assessing which groups are negatively impacted by a model, and for comparing multiple models in terms of various fairness and accuracy metrics."
- "[Algorithms](https://fairlearn.org/main/user_guide/mitigation.html) for mitigating unfairness in a variety of AI tasks and along a variety of fairness definitions."

Highlight:

> Fairness is a fundamentally sociotechnical challenge and cannot be solved with technical tools alone. They may be helpful for certain tasks such as assessing unfairness through various metrics, or to mitigate observed unfairness when training a model. Additionally, fairness has different definitions in different contexts and it may not be possible to represent it quantitatively at all. [source](https://fairlearn.org/main/quickstart.html)
