<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>PaddlePaddle on Ethical AI Tool Landscape</title><link>https://edwinwenink.github.io/ai-ethics-tool-landscape/frameworks/paddlepaddle/</link><description>Recent content in PaddlePaddle on Ethical AI Tool Landscape</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Edwin Wenink</copyright><atom:link href="https://edwinwenink.github.io/ai-ethics-tool-landscape/frameworks/paddlepaddle/index.xml" rel="self" type="application/rss+xml"/><item><title>AdvBox</title><link>https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/advbox/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://edwinwenink.github.io/ai-ethics-tool-landscape/tools/advbox/</guid><description>Advbox offers a number of AI model security toolkits. AdversialBox allows zero-coding generation of adversial examples for a wide range of neural network frameworks. An overview of the supported attacks and defenses can be found here and the corresponding code here. It requires some effort to find all attacks mentioned on the homepage in the code base.
Generally speaking, the documentation of AdvBox is incomplete and not very user-friendly. ODD: Object Detector Deception showcases a specific attack for object detection networks such as YOLO, but is not mentioned in the README.</description></item></channel></rss>