<!DOCTYPE html>
<html lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>InterpretML</title>
	
	
	<link rel="stylesheet" href="/css/style.css">
	
</head>
<body>
	<header>
    <div class='inline-block'>
        <a href="https://github.com/EdwinWenink/ai-ethics-tool-landscape"><img src='/img/GitHub-Mark/PNG/GitHub-Mark-32px.png' alt="Github page" class='inline-logo'></a>
    </div>
	<nav>
        <a href="http://example.org/">Ethical AI Tool Landscape</a>
        
                
                > <a href="/values/">Values</a> 
                
                > <a href="/stages/">Stages</a> 
                
                > <a href="/categories/">Categories</a> 
                
                > <a href="/tools/">Tools</a> 
                
                > <a href="/taxonomy/">Taxonomy</a> 
                
        
	</nav>
</header>

	
	<main>
		<article>
			<h1 class="title">InterpretML</h1>
            

			<div>

            

            <ul>
                
                <li id="values"> Values: { 
                    
                        <a href="/values/explainability">explainability</a>
                     } 
                 

                    
                    
                    <ul>
                        <li>Explanation type: { <a href="/explanations/white-box">white box</a> <a href="/explanations/shapley-value">Shapley value</a> <a href="/explanations/partial-dependence-plot">partial dependence plot</a> <a href="/explanations/sensitivity-analysis">sensitivity analysis</a>  }</li>
                    </ul>
                    

                    
                    
                </li> 

                
                <li id="categories"> Categories: {  <a href="/categories/model-agnostic">model-agnostic</a> <a href="/categories/model-specific">model-specific</a> } </li>
                 

                
                <li id="design-phase"> Design stage: {  <a href="/stages/learning">learning</a> <a href="/stages/post-hoc">post-hoc</a> }</li> 
                 

                
                <li id="repository"> Repository: <a href="https://github.com/interpretml/interpret" target="_blank">https://github.com/interpretml/interpret</a></li>
                 

                
                <li id="model">Tasks: {  <a href="/tasks/classification">classification</a> <a href="/tasks/regression">regression</a> }</li> 
                 

                
                <li id="model">Input data: {  <a href="/data/tabular">tabular</a> <a href="/data/text">text</a> <a href="/data/image">image</a> }</li> 
                 

                
                <li id="licence"> Licence: MIT</li>
                 

                
                <li id="languages"> Languages: { <a href="/languages/python">Python</a>  }</li>
                 

                
                <li id="references">References: 
                    
                    
                        
                        <ul> 
                            <li><a href="https://arxiv.org/abs/1909.09223">Nori et al. - InterpretML: A Unified Framework for Machine Learning Interpretability</a></li>
                        </ul>
                        
                     
                </li>
                 

                

            </ul>
			</div>

            <hr>

			<div>
				<p>The InterpretML toolkit, developed at Microsoft, can be decomposed in two major components:</p>
<ol>
<li>A set of interpretable &ldquo;glassbox&rdquo; models</li>
<li>Techniques for explaining black box systems.</li>
</ol>
<p>W.r.t. 1, InterpretML particularly contains a new interpretable &ldquo;glassbox&rdquo; model that combines Generalized Additive Models (GAMs) with machine learning techniques such as gradient boosted trees, called an <em>Explainable Boosting Machine</em>.</p>
<p>Other than this new interpretable model, the main utility of InterpretML is to unify existing explainability techniques under a single API.</p>
<p>

<a href="/tools/interpret-text/">Interpret-Text</a>
 is an extension of InterpretML to support various text models.</p>
<h2 id="glassbox-models">Glassbox models</h2>
<ul>
<li>Explainable Boosting Machine</li>
<li>Decision tree</li>
<li>Decision rule list</li>
<li>Linear/logistic regression</li>
</ul>
<h2 id="blackbox-explainers">Blackbox explainers</h2>
<ul>
<li>SHAP kernel explainer</li>
<li>SHAP tree explainer</li>
<li>

<a href="/tools/lime/">LIME</a>
</li>
<li>Morris sensitivity analysis</li>
<li>Partial dependence plots</li>
</ul>
<p>So this package contains both 

<a href="/categories/model-agnostic/">model-agnostic</a>
 and 

<a href="/categories/model-specific/">model-specific</a>
 explainers.</p>

			</div>
		</article>
	</main>
    

	<footer>
    Last modified on 21-05-2021.
    <p>&copy; 2021 <a href="http://example.org/">Ethical AI Tool Landscape</a> curated by <a href=https://www.edwinwenink.xyz>Edwin Wenink</a></p>
</footer>

</body>
</html>
